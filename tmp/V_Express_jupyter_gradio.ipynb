{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "L4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nekoniii3/Colabo_Samples/blob/main/tmp/V_Express_jupyter_gradio.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **V_Express-Jupyter-Gradio**\n",
        "This is a modification of https://colab.research.google.com/github/camenduru/V-Express-jupyter/"
      ],
      "metadata": {
        "id": "k2HX4TkVj3C1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VjYy0F2gZIPR"
      },
      "outputs": [],
      "source": [
        "%cd /content\n",
        "!git clone -b dev https://github.com/camenduru/V-Express\n",
        "%cd /content/V-Express\n",
        "\n",
        "!apt -y install -qq aria2\n",
        "\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/camenduru/V-Express/resolve/main/insightface_models/models/buffalo_l/1k3d68.onnx -d /content/V-Express/model_ckpts/insightface_models/models/buffalo_l -o 1k3d68.onnx\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/camenduru/V-Express/resolve/main/insightface_models/models/buffalo_l/2d106det.onnx -d /content/V-Express/model_ckpts/insightface_models/models/buffalo_l -o 2d106det.onnx\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/camenduru/V-Express/resolve/main/insightface_models/models/buffalo_l/det_10g.onnx -d /content/V-Express/model_ckpts/insightface_models/models/buffalo_l -o det_10g.onnx\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/camenduru/V-Express/resolve/main/insightface_models/models/buffalo_l/genderage.onnx -d /content/V-Express/model_ckpts/insightface_models/models/buffalo_l -o genderage.onnx\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/camenduru/V-Express/resolve/main/insightface_models/models/buffalo_l/w600k_r50.onnx -d /content/V-Express/model_ckpts/insightface_models/models/buffalo_l -o w600k_r50.onnx\n",
        "\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/camenduru/V-Express/raw/main/sd-vae-ft-mse/config.json -d /content/V-Express/model_ckpts/sd-vae-ft-mse -o config.json\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/camenduru/V-Express/resolve/main/sd-vae-ft-mse/diffusion_pytorch_model.bin -d /content/V-Express/model_ckpts/sd-vae-ft-mse -o diffusion_pytorch_model.bin\n",
        "\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/camenduru/V-Express/raw/main/stable-diffusion-v1-5/unet/config.json -d /content/V-Express/model_ckpts/stable-diffusion-v1-5/unet -o config.json\n",
        "\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/camenduru/V-Express/resolve/main/v-express/audio_projection.pth -d /content/V-Express/model_ckpts/v-express -o audio_projection.pth\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/camenduru/V-Express/resolve/main/v-express/denoising_unet.pth -d /content/V-Express/model_ckpts/v-express -o denoising_unet.pth\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/camenduru/V-Express/resolve/main/v-express/motion_module.pth -d /content/V-Express/model_ckpts/v-express -o motion_module.pth\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/camenduru/V-Express/resolve/main/v-express/reference_net.pth -d /content/V-Express/model_ckpts/v-express -o reference_net.pth\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/camenduru/V-Express/resolve/main/v-express/v_kps_guider.pth -d /content/V-Express/model_ckpts/v-express -o v_kps_guider.pth\n",
        "\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/camenduru/V-Express/raw/main/wav2vec2-base-960h/config.json -d /content/V-Express/model_ckpts/wav2vec2-base-960h -o config.json\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/camenduru/V-Express/raw/main/wav2vec2-base-960h/feature_extractor_config.json -d /content/V-Express/model_ckpts/wav2vec2-base-960h -o feature_extractor_config.json\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/camenduru/V-Express/raw/main/wav2vec2-base-960h/preprocessor_config.json -d /content/V-Express/model_ckpts/wav2vec2-base-960h -o preprocessor_config.json\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/camenduru/V-Express/resolve/main/wav2vec2-base-960h/pytorch_model.bin -d /content/V-Express/model_ckpts/wav2vec2-base-960h -o pytorch_model.bin\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/camenduru/V-Express/raw/main/wav2vec2-base-960h/special_tokens_map.json -d /content/V-Express/model_ckpts/wav2vec2-base-960h -o special_tokens_map.json\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/camenduru/V-Express/raw/main/wav2vec2-base-960h/tokenizer_config.json -d /content/V-Express/model_ckpts/wav2vec2-base-960h -o tokenizer_config.json\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/camenduru/V-Express/raw/main/wav2vec2-base-960h/vocab.json -d /content/V-Express/model_ckpts/wav2vec2-base-960h -o vocab.json\n",
        "\n",
        "!pip install diffusers==0.24.0 imageio-ffmpeg==0.4.9 insightface==0.7.3 omegaconf==2.2.3 onnxruntime==1.16.3 safetensors==0.4.2 transformers==4.30.2 einops==0.4.1 tqdm==4.66.1 xformers==0.0.26.post1 av accelerate\n",
        "\n",
        "# Gradio追加\n",
        "!pip install gradio==4.32.1"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **①画像と音声のみで動画を生成（シナリオ2）**\n",
        "Generate videos using only images and audio（Scenario2）"
      ],
      "metadata": {
        "id": "fWE5P16bjF3E"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WGORu9Pv5cO5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 669
        },
        "outputId": "215017ad-a0ce-47c9-b38a-604f5f290531"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/V-Express\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "Running on public URL: https://5b7c030883c81c6944.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://5b7c030883c81c6944.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7860 <> https://5b7c030883c81c6944.gradio.live\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "%cd /content/V-Express\n",
        "\n",
        "import gradio as gr\n",
        "import os\n",
        "import datetime\n",
        "from zoneinfo import ZoneInfo\n",
        "\n",
        "dt = datetime.datetime.now(ZoneInfo(\"Asia/Tokyo\"))\n",
        "fol_name = dt.strftime(\"%Y%m%d%H%M%S\")\n",
        "\n",
        "def fix_face_video(input_image, input_audio):\n",
        "\n",
        "    retarget_strategy = \"fix_face\"\n",
        "    num_inference_steps = 25\n",
        "\n",
        "    dt = datetime.datetime.now(ZoneInfo(\"Asia/Tokyo\"))\n",
        "    fol_name = dt.strftime(\"%Y%m%d\")\n",
        "    file_name = dt.strftime(\"%H%M%S\")\n",
        "\n",
        "    out_video = \"./output/\" + fol_name+ \"/fix_face_\" + file_name + \".mp4\"\n",
        "    # print(\"out_video_name：\"out_video)\n",
        "\n",
        "    !python inference.py \\\n",
        "        --reference_image_path $input_image \\\n",
        "        --audio_path $input_audio \\\n",
        "        --output_path $out_video \\\n",
        "        --retarget_strategy $retarget_strategy \\\n",
        "        --num_inference_steps $num_inference_steps\n",
        "\n",
        "    return out_video\n",
        "\n",
        "image = gr.Image(label=\"対象画像(jpg, png)\", type=\"filepath\")\n",
        "audio = gr.File(label=\"音声ファイル(mp3)\", file_types=[\".mp3\", \".MP3\"])\n",
        "out_video = gr.Video(label=\"Fix Face Video\")\n",
        "btn = gr.Button(\"送信\", variant=\"primary\")\n",
        "\n",
        "title = \"V_Express Scenario2\"\n",
        "description = \"<div style='text-align: center;'><h3>これは公式のシナリオ2（画像と話す音声による生成）のみ対応しています。\"\n",
        "description += \"<br>This only supports official Scenario 2 (A's picture and any talking audio).</h3></div>\"\n",
        "\n",
        "demo = gr.Interface(\n",
        "    fn=fix_face_video,\n",
        "    inputs=[image, audio],\n",
        "    outputs=[out_video],\n",
        "    title=title,\n",
        "    submit_btn=btn,\n",
        "    clear_btn=None,\n",
        "    description=description,\n",
        "    allow_flagging=\"never\"\n",
        ")\n",
        "\n",
        "demo.queue()\n",
        "demo.launch(share=True, debug=True)"
      ]
    }
  ]
}