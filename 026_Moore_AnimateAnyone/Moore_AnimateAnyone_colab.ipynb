{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nekoniii3/Colabo_Samples/blob/main/026_Moore_AnimateAnyone/Moore_AnimateAnyone_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **※最初にランタイムからタイプをGPUに変更して下さい。**"
      ],
      "metadata": {
        "id": "0rnnQPNAYknl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **①Moore_AnimateAnyoneインストールなど**"
      ],
      "metadata": {
        "id": "tt-IhU8NZp8O"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VjYy0F2gZIPR"
      },
      "outputs": [],
      "source": [
        "%cd /content\n",
        "!git clone -b dev https://github.com/camenduru/Moore-AnimateAnyone\n",
        "%cd /content/Moore-AnimateAnyone\n",
        "\n",
        "!pip install -q gradio==3.50.2 diffusers==0.24.0 av==11.0.0 decord==0.6.0 einops==0.4.1 accelerate==0.21.0\n",
        "!pip install -q omegaconf==2.2.3\n",
        "!pip install -q https://github.com/openai/CLIP/archive/d50d76daa670286dd6cacf3bcd80b5e4823fc8e1.zip\n",
        "\n",
        "!apt -y install -qq aria2\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/camenduru/AnimateAnyone/raw/main/stable-diffusion-v1-5/model_index.json -d /content/Moore-AnimateAnyone/pretrained_weights/stable-diffusion-v1-5 -o model_index.json\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/camenduru/AnimateAnyone/raw/main/stable-diffusion-v1-5/unet/config.json -d /content/Moore-AnimateAnyone/pretrained_weights/stable-diffusion-v1-5/unet -o config.json\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/camenduru/AnimateAnyone/resolve/main/stable-diffusion-v1-5/unet/diffusion_pytorch_model.bin -d /content/Moore-AnimateAnyone/pretrained_weights/stable-diffusion-v1-5/unet -o diffusion_pytorch_model.bin\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/camenduru/AnimateAnyone/raw/main/stable-diffusion-v1-5/v1-inference.yaml -d /content/Moore-AnimateAnyone/pretrained_weights/stable-diffusion-v1-5 -o v1-inference.yaml\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/camenduru/AnimateAnyone/raw/main/stable-diffusion-v1-5/feature_extractor/preprocessor_config.json -d /content/Moore-AnimateAnyone/pretrained_weights/stable-diffusion-v1-5/feature_extractor -o preprocessor_config.json\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/patrolli/AnimateAnyone/resolve/main/denoising_unet.pth -d /content/Moore-AnimateAnyone/pretrained_weights -o denoising_unet.pth\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/patrolli/AnimateAnyone/resolve/main/motion_module.pth -d /content/Moore-AnimateAnyone/pretrained_weights -o motion_module.pth\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/patrolli/AnimateAnyone/resolve/main/pose_guider.pth -d /content/Moore-AnimateAnyone/pretrained_weights -o pose_guider.pth\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/patrolli/AnimateAnyone/resolve/main/reference_unet.pth -d /content/Moore-AnimateAnyone/pretrained_weights -o reference_unet.pth\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/stabilityai/sd-vae-ft-mse/raw/main/config.json -d /content/Moore-AnimateAnyone/pretrained_weights/sd-vae-ft-mse -o config.json\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/stabilityai/sd-vae-ft-mse/resolve/main/diffusion_pytorch_model.bin -d /content/Moore-AnimateAnyone/pretrained_weights/sd-vae-ft-mse -o diffusion_pytorch_model.bin\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/stabilityai/sd-vae-ft-mse/resolve/main/diffusion_pytorch_model.safetensors -d /content/Moore-AnimateAnyone/pretrained_weights/sd-vae-ft-mse -o diffusion_pytorch_model.safetensors\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/lambdalabs/sd-image-variations-diffusers/raw/main/image_encoder/config.json -d /content/Moore-AnimateAnyone/pretrained_weights/image_encoder -o config.json\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/lambdalabs/sd-image-variations-diffusers/resolve/main/image_encoder/pytorch_model.bin -d /content/Moore-AnimateAnyone/pretrained_weights/image_encoder -o pytorch_model.bin\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/camenduru/AnimateAnyone/resolve/main/dw-ll_ucoco_384.onnx -d /content/Moore-AnimateAnyone/pretrained_weights/DWPose -o dw-ll_ucoco_384.onnx\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/camenduru/AnimateAnyone/resolve/main/yolox_l.onnx -d /content/Moore-AnimateAnyone/pretrained_weights/DWPose -o yolox_l.onnx\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **②Moore_AnimateAnyone起動**"
      ],
      "metadata": {
        "id": "Fi7f6q-vZhrC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python app.py"
      ],
      "metadata": {
        "id": "xuNfMTqPFLEi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **（補足）Motion Sequence作成アプリ起動<br>※①の後に行ってください（②は停止させる）**"
      ],
      "metadata": {
        "id": "muJjrVdhYuWA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **1.追加インストール**"
      ],
      "metadata": {
        "id": "30mECGEcH-bU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install controlnet_aux\n",
        "!pip install onnxruntime-gpu"
      ],
      "metadata": {
        "id": "XbnKxYksHTZQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **2.モーション作成アプリ起動**"
      ],
      "metadata": {
        "id": "gNT0I9RjIDzU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import gradio as gr\n",
        "from src.dwpose import DWposeDetector\n",
        "from pathlib import Path\n",
        "from src.utils.util import get_fps, read_frames, save_videos_from_pil\n",
        "import numpy as np\n",
        "\n",
        "def process_video(input_video_path):\n",
        "\n",
        "    print(input_video_path)\n",
        "    video_name = os.path.splitext(os.path.basename(input_video_path))[0]\n",
        "\n",
        "    dir_path = \"vid2pose\"\n",
        "    os.makedirs(dir_path, exist_ok=True)\n",
        "    # path = os.getcwd()\n",
        "    out_path = os.path.join(dir_path, video_name + \"_kps.mp4\")\n",
        "    #configs/inference/pose_videos/man.mp4\n",
        "\n",
        "    detector = DWposeDetector()\n",
        "    detector = detector.to(f\"cuda\")\n",
        "\n",
        "    fps = get_fps(input_video_path)\n",
        "    frames = read_frames(input_video_path)\n",
        "    kps_results = []\n",
        "    for i, frame_pil in enumerate(frames):\n",
        "        result, score = detector(frame_pil)\n",
        "        score = np.mean(score, axis=-1)\n",
        "\n",
        "        kps_results.append(result)\n",
        "\n",
        "    print(out_path)\n",
        "    save_videos_from_pil(kps_results, out_path, fps=fps)\n",
        "\n",
        "    return out_path\n",
        "\n",
        "iface = gr.Interface(\n",
        "    fn=process_video,\n",
        "    inputs=gr.Video(label=\"Input Video\"),\n",
        "    outputs=gr.Video(label=\"Output Video\"),\n",
        "    title=\"Video\"\n",
        ")\n",
        "iface.queue()\n",
        "iface.launch(share=True, inline=False, debug=True)"
      ],
      "metadata": {
        "id": "MffXgwEkiesV"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V100",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}